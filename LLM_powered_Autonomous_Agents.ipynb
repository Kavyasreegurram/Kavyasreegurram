{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kavyasreegurram/Kavyasreegurram/blob/main/LLM_powered_Autonomous_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## LLM-Powered Autonomous Agents\n",
        "Name- Kavyasree Gurram\n",
        "ID-2940627\n"
      ],
      "metadata": {
        "id": "Zt2t8elVxrfZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CrmUJ_hNQEO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain==0.2.5 langchain-community==0.2.5 #sentence-transformers==3.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeting Up LLM"
      ],
      "metadata": {
        "id": "QWO2uDoovLL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python==0.2.78  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f7AG9l3Nett",
        "outputId": "2cc00d1b-30c7-479c-aa1a-c18dc0035dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu124\n",
            "Requirement already satisfied: llama-cpp-python==0.2.78 in /usr/local/lib/python3.12/dist-packages (0.2.78)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.78) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.78) (1.26.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.78) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python==0.2.78) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.78) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT8TwMSGu0Rr",
        "outputId": "ec8a2606-51f7-4e13-a45d-7c0a40cdc7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-17 12:14:34--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 108.157.142.53, 108.157.142.55, 108.157.142.50, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.157.142.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/df220524a4e4a750fe1c325e41f09ff69137f38b52d8831ba22dcbee3cc8ab6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251117T121434Z&X-Amz-Expires=3600&X-Amz-Signature=8b01fc9a726fa3ce5a8f5df609746456d32f4ac13bd8162bf3d916eed9eced19&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&x-id=GetObject&Expires=1763385274&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MzM4NTI3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvZGYyMjA1MjRhNGU0YTc1MGZlMWMzMjVlNDFmMDlmZjY5MTM3ZjM4YjUyZDg4MzFiYTIyZGNiZWUzY2M4YWI2ZCoifV19&Signature=bjl%7EZTr9sC%7EQkw1527i8eQrTBMRVJ4Ca-pWzy6QdKhgxm2nfadLrUE-QMtm0mCHPwzdkTCLf7K6SCBH06uAj%7Eoi8BvAcLSFTUYs%7Ez-EDK%7EUiUo2e3x7V0wPnqpKY8IqbEfX4PAQjI5l5n42Twwr9LkRyLJN4KQbh7-aAl27QaOzTTACMarxbVFocR02PXZcCE1eJW97aHZDjseIAsCCqIXLSmbvxeRZk%7EqrvCl8hO8vr1ye4-rp5ERnbEQIjVbE0hXuJc-Ynp0AqCfr2adA1EW--lw3QVKbmpwpiXeZMjlUJyft9TqlGESonB%7E-3SbLkKfyoMFvEqcke2pMo81s4xA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-11-17 12:14:34--  https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/df220524a4e4a750fe1c325e41f09ff69137f38b52d8831ba22dcbee3cc8ab6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251117T121434Z&X-Amz-Expires=3600&X-Amz-Signature=8b01fc9a726fa3ce5a8f5df609746456d32f4ac13bd8162bf3d916eed9eced19&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&x-id=GetObject&Expires=1763385274&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MzM4NTI3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvZGYyMjA1MjRhNGU0YTc1MGZlMWMzMjVlNDFmMDlmZjY5MTM3ZjM4YjUyZDg4MzFiYTIyZGNiZWUzY2M4YWI2ZCoifV19&Signature=bjl%7EZTr9sC%7EQkw1527i8eQrTBMRVJ4Ca-pWzy6QdKhgxm2nfadLrUE-QMtm0mCHPwzdkTCLf7K6SCBH06uAj%7Eoi8BvAcLSFTUYs%7Ez-EDK%7EUiUo2e3x7V0wPnqpKY8IqbEfX4PAQjI5l5n42Twwr9LkRyLJN4KQbh7-aAl27QaOzTTACMarxbVFocR02PXZcCE1eJW97aHZDjseIAsCCqIXLSmbvxeRZk%7EqrvCl8hO8vr1ye4-rp5ERnbEQIjVbE0hXuJc-Ynp0AqCfr2adA1EW--lw3QVKbmpwpiXeZMjlUJyft9TqlGESonB%7E-3SbLkKfyoMFvEqcke2pMo81s4xA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.173.166.85, 18.173.166.82, 18.173.166.74, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.173.166.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2393231072 (2.2G)\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-q4.gguf.2’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   2.23G   169MB/s    in 26s     \n",
            "\n",
            "2025-11-17 12:15:00 (87.5 MB/s) - ‘Phi-3-mini-4k-instruct-q4.gguf.2’ saved [2393231072/2393231072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool, AgentType"
      ],
      "metadata": {
        "id": "bdd4P7RyPYDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp"
      ],
      "metadata": {
        "id": "wmb2ZCF1Xkog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading LLM\n",
        "Laoad LLM of your choice."
      ],
      "metadata": {
        "id": "tMFUnQ6UzOeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load LLM Local for example Phi-3 Mini 4K gguf Model\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
        "    n_gpu_layers=-1,  # full GPU\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,\n",
        "    temperature=0.1,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "2Yjx0T9WQUm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exampledefination of a tool\n",
        "\n",
        "def add_numbers(q):\n",
        "    nums = [int(x) for x in q.split() if x.isdigit()]\n",
        "    return f\"Sum = {sum(nums)}\"\n",
        "\n",
        "# Use of tool\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Addition Tool\",\n",
        "        func=add_numbers,\n",
        "        description=\"Useful for adding integers in a query. Input should contain numbers.\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "LlEyoCkSYe2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for more then one tools use the follwing\n",
        "'''\n",
        "tools.append(\n",
        "   Tool(\n",
        "       name=\"name of tool\",\n",
        "       func=function call,\n",
        "       description=\"Useful tool to search ---.\",\n",
        "   )\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "TlLyzufu0tK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create template\n",
        "\n",
        "the template will serve as instructions to LLM"
      ],
      "metadata": {
        "id": "nb-WLCnRbQXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "IxYYY2kkaHp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and Execute Agent"
      ],
      "metadata": {
        "id": "QZPVkV5o1zpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_react_agent"
      ],
      "metadata": {
        "id": "vNfc1Ssp1n63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt\n",
        ")"
      ],
      "metadata": {
        "id": "oIKYUkueZvBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    max_iterations=1,\n",
        "    handle_parsing_errors=True\n",
        ")"
      ],
      "metadata": {
        "id": "DXxj7xNka47w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"7 7\"\n",
        "\n",
        "response = agent_executor.invoke({\"input\": query})\n",
        "print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVoQ2Sca9WP",
        "outputId": "e288e66f-f027-443f-ceb2-906ea2d7edf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "<|assistant|> Question: What is the sum of 7 and 7?\n",
            "Thought: To find the sum, I will use the Addition Tool.\n",
            "Action: Addition Tool\n",
            "Action Input: 7 + 7\u001b[0m\u001b[36;1m\u001b[1;3mSum = 14\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    }
  ]
}